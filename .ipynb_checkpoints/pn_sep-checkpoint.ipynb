{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import numpy as np\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCN(\n",
      "  (fc): ModuleList(\n",
      "    (0): Linear(in_features=784, out_features=200, bias=True)\n",
      "    (1): Linear(in_features=200, out_features=200, bias=True)\n",
      "    (2): Linear(in_features=200, out_features=10, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class FCN(nn.Module):\n",
    "    def __init__(self,num_layers,num_nodes):\n",
    "        super(FCN,self).__init__()\n",
    "        if num_layers!=len(num_nodes)-1:\n",
    "            sys.exit(\"Miss Match on number of layers\")\n",
    "        self.num_lay=num_layers\n",
    "        self.num_nodes=num_nodes\n",
    "        self.fc=nn.ModuleList()\n",
    "        for i in range(num_layers):\n",
    "            self.fc.append(nn.Linear(num_nodes[i],num_nodes[i+1]))\n",
    "    \n",
    "    def forward(self,x):\n",
    "        for i in range(self.num_lay-1):\n",
    "            x=F.relu(self.fc[i](x))\n",
    "        x=self.fc[self.num_lay-1](x)\n",
    "        return F.log_softmax(x)\n",
    "    \n",
    "    def print_param(self):\n",
    "        net_W=[]\n",
    "        net_b=[]\n",
    "        for i in range(self.num_lay):\n",
    "            net_W.append(self.fc[i].weight.data)\n",
    "            net_b.append(self.fc[i].bias.data)\n",
    "            #print(self.fc[i].weight.data)\n",
    "            #print(self.fc[i].bias.data)\n",
    "            \n",
    "        return [net_W,net_b]\n",
    "        \n",
    "    \n",
    "\n",
    "fcn_i1=FCN(3,[784,200,200,10])\n",
    "print(fcn_i1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [0/60000 (0%)]\tLoss: 2.303550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kushal/anaconda3/envs/ece587_ptc/lib/python3.6/site-packages/ipykernel_launcher.py:16: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [2000/60000 (3%)]\tLoss: 2.196492\n",
      "Train Epoch: 0 [4000/60000 (7%)]\tLoss: 1.906543\n",
      "Train Epoch: 0 [6000/60000 (10%)]\tLoss: 1.382495\n",
      "Train Epoch: 0 [8000/60000 (13%)]\tLoss: 0.817513\n",
      "Train Epoch: 0 [10000/60000 (17%)]\tLoss: 0.559991\n",
      "Train Epoch: 0 [12000/60000 (20%)]\tLoss: 0.483807\n",
      "Train Epoch: 0 [14000/60000 (23%)]\tLoss: 0.492059\n",
      "Train Epoch: 0 [16000/60000 (27%)]\tLoss: 0.557322\n",
      "Train Epoch: 0 [18000/60000 (30%)]\tLoss: 0.310246\n",
      "Train Epoch: 0 [20000/60000 (33%)]\tLoss: 0.344332\n",
      "Train Epoch: 0 [22000/60000 (37%)]\tLoss: 0.270693\n",
      "Train Epoch: 0 [24000/60000 (40%)]\tLoss: 0.375889\n",
      "Train Epoch: 0 [26000/60000 (43%)]\tLoss: 0.417425\n",
      "Train Epoch: 0 [28000/60000 (47%)]\tLoss: 0.358415\n",
      "Train Epoch: 0 [30000/60000 (50%)]\tLoss: 0.306260\n",
      "Train Epoch: 0 [32000/60000 (53%)]\tLoss: 0.312557\n",
      "Train Epoch: 0 [34000/60000 (57%)]\tLoss: 0.294137\n",
      "Train Epoch: 0 [36000/60000 (60%)]\tLoss: 0.343559\n",
      "Train Epoch: 0 [38000/60000 (63%)]\tLoss: 0.359222\n",
      "Train Epoch: 0 [40000/60000 (67%)]\tLoss: 0.296853\n",
      "Train Epoch: 0 [42000/60000 (70%)]\tLoss: 0.248724\n",
      "Train Epoch: 0 [44000/60000 (73%)]\tLoss: 0.245376\n",
      "Train Epoch: 0 [46000/60000 (77%)]\tLoss: 0.306102\n",
      "Train Epoch: 0 [48000/60000 (80%)]\tLoss: 0.336472\n",
      "Train Epoch: 0 [50000/60000 (83%)]\tLoss: 0.291997\n",
      "Train Epoch: 0 [52000/60000 (87%)]\tLoss: 0.362154\n",
      "Train Epoch: 0 [54000/60000 (90%)]\tLoss: 0.267991\n",
      "Train Epoch: 0 [56000/60000 (93%)]\tLoss: 0.319032\n",
      "Train Epoch: 0 [58000/60000 (97%)]\tLoss: 0.296162\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.190285\n",
      "Train Epoch: 1 [2000/60000 (3%)]\tLoss: 0.319115\n",
      "Train Epoch: 1 [4000/60000 (7%)]\tLoss: 0.256089\n",
      "Train Epoch: 1 [6000/60000 (10%)]\tLoss: 0.176325\n",
      "Train Epoch: 1 [8000/60000 (13%)]\tLoss: 0.235678\n",
      "Train Epoch: 1 [10000/60000 (17%)]\tLoss: 0.197733\n",
      "Train Epoch: 1 [12000/60000 (20%)]\tLoss: 0.140448\n",
      "Train Epoch: 1 [14000/60000 (23%)]\tLoss: 0.193062\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tLoss: 0.121003\n",
      "Train Epoch: 1 [18000/60000 (30%)]\tLoss: 0.239389\n",
      "Train Epoch: 1 [20000/60000 (33%)]\tLoss: 0.184944\n",
      "Train Epoch: 1 [22000/60000 (37%)]\tLoss: 0.191022\n",
      "Train Epoch: 1 [24000/60000 (40%)]\tLoss: 0.261249\n",
      "Train Epoch: 1 [26000/60000 (43%)]\tLoss: 0.234612\n",
      "Train Epoch: 1 [28000/60000 (47%)]\tLoss: 0.183927\n",
      "Train Epoch: 1 [30000/60000 (50%)]\tLoss: 0.208346\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.213318\n",
      "Train Epoch: 1 [34000/60000 (57%)]\tLoss: 0.248582\n",
      "Train Epoch: 1 [36000/60000 (60%)]\tLoss: 0.111043\n",
      "Train Epoch: 1 [38000/60000 (63%)]\tLoss: 0.221555\n",
      "Train Epoch: 1 [40000/60000 (67%)]\tLoss: 0.185310\n",
      "Train Epoch: 1 [42000/60000 (70%)]\tLoss: 0.166328\n",
      "Train Epoch: 1 [44000/60000 (73%)]\tLoss: 0.205130\n",
      "Train Epoch: 1 [46000/60000 (77%)]\tLoss: 0.098790\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.210580\n",
      "Train Epoch: 1 [50000/60000 (83%)]\tLoss: 0.126853\n",
      "Train Epoch: 1 [52000/60000 (87%)]\tLoss: 0.212473\n",
      "Train Epoch: 1 [54000/60000 (90%)]\tLoss: 0.259583\n",
      "Train Epoch: 1 [56000/60000 (93%)]\tLoss: 0.157424\n",
      "Train Epoch: 1 [58000/60000 (97%)]\tLoss: 0.231083\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.198991\n",
      "Train Epoch: 2 [2000/60000 (3%)]\tLoss: 0.091976\n",
      "Train Epoch: 2 [4000/60000 (7%)]\tLoss: 0.159041\n",
      "Train Epoch: 2 [6000/60000 (10%)]\tLoss: 0.164266\n",
      "Train Epoch: 2 [8000/60000 (13%)]\tLoss: 0.202059\n",
      "Train Epoch: 2 [10000/60000 (17%)]\tLoss: 0.076265\n",
      "Train Epoch: 2 [12000/60000 (20%)]\tLoss: 0.177813\n",
      "Train Epoch: 2 [14000/60000 (23%)]\tLoss: 0.191711\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.171482\n",
      "Train Epoch: 2 [18000/60000 (30%)]\tLoss: 0.144693\n",
      "Train Epoch: 2 [20000/60000 (33%)]\tLoss: 0.192317\n",
      "Train Epoch: 2 [22000/60000 (37%)]\tLoss: 0.138845\n",
      "Train Epoch: 2 [24000/60000 (40%)]\tLoss: 0.128804\n",
      "Train Epoch: 2 [26000/60000 (43%)]\tLoss: 0.089381\n",
      "Train Epoch: 2 [28000/60000 (47%)]\tLoss: 0.086095\n",
      "Train Epoch: 2 [30000/60000 (50%)]\tLoss: 0.187857\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.199619\n",
      "Train Epoch: 2 [34000/60000 (57%)]\tLoss: 0.178690\n",
      "Train Epoch: 2 [36000/60000 (60%)]\tLoss: 0.127477\n",
      "Train Epoch: 2 [38000/60000 (63%)]\tLoss: 0.097013\n",
      "Train Epoch: 2 [40000/60000 (67%)]\tLoss: 0.084587\n",
      "Train Epoch: 2 [42000/60000 (70%)]\tLoss: 0.179819\n",
      "Train Epoch: 2 [44000/60000 (73%)]\tLoss: 0.124492\n",
      "Train Epoch: 2 [46000/60000 (77%)]\tLoss: 0.126961\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.153049\n",
      "Train Epoch: 2 [50000/60000 (83%)]\tLoss: 0.060489\n",
      "Train Epoch: 2 [52000/60000 (87%)]\tLoss: 0.096864\n",
      "Train Epoch: 2 [54000/60000 (90%)]\tLoss: 0.127350\n",
      "Train Epoch: 2 [56000/60000 (93%)]\tLoss: 0.082689\n",
      "Train Epoch: 2 [58000/60000 (97%)]\tLoss: 0.122850\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.138146\n",
      "Train Epoch: 3 [2000/60000 (3%)]\tLoss: 0.107212\n",
      "Train Epoch: 3 [4000/60000 (7%)]\tLoss: 0.098439\n",
      "Train Epoch: 3 [6000/60000 (10%)]\tLoss: 0.125234\n",
      "Train Epoch: 3 [8000/60000 (13%)]\tLoss: 0.097531\n",
      "Train Epoch: 3 [10000/60000 (17%)]\tLoss: 0.149899\n",
      "Train Epoch: 3 [12000/60000 (20%)]\tLoss: 0.163303\n",
      "Train Epoch: 3 [14000/60000 (23%)]\tLoss: 0.070499\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.137614\n",
      "Train Epoch: 3 [18000/60000 (30%)]\tLoss: 0.091188\n",
      "Train Epoch: 3 [20000/60000 (33%)]\tLoss: 0.169604\n",
      "Train Epoch: 3 [22000/60000 (37%)]\tLoss: 0.065631\n",
      "Train Epoch: 3 [24000/60000 (40%)]\tLoss: 0.142007\n",
      "Train Epoch: 3 [26000/60000 (43%)]\tLoss: 0.108769\n",
      "Train Epoch: 3 [28000/60000 (47%)]\tLoss: 0.109992\n",
      "Train Epoch: 3 [30000/60000 (50%)]\tLoss: 0.122443\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.100848\n",
      "Train Epoch: 3 [34000/60000 (57%)]\tLoss: 0.144809\n",
      "Train Epoch: 3 [36000/60000 (60%)]\tLoss: 0.083121\n",
      "Train Epoch: 3 [38000/60000 (63%)]\tLoss: 0.118153\n",
      "Train Epoch: 3 [40000/60000 (67%)]\tLoss: 0.134492\n",
      "Train Epoch: 3 [42000/60000 (70%)]\tLoss: 0.171960\n",
      "Train Epoch: 3 [44000/60000 (73%)]\tLoss: 0.092851\n",
      "Train Epoch: 3 [46000/60000 (77%)]\tLoss: 0.047598\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.065584\n",
      "Train Epoch: 3 [50000/60000 (83%)]\tLoss: 0.137078\n",
      "Train Epoch: 3 [52000/60000 (87%)]\tLoss: 0.058113\n",
      "Train Epoch: 3 [54000/60000 (90%)]\tLoss: 0.099856\n",
      "Train Epoch: 3 [56000/60000 (93%)]\tLoss: 0.059814\n",
      "Train Epoch: 3 [58000/60000 (97%)]\tLoss: 0.111988\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.063486\n",
      "Train Epoch: 4 [2000/60000 (3%)]\tLoss: 0.045019\n",
      "Train Epoch: 4 [4000/60000 (7%)]\tLoss: 0.127550\n",
      "Train Epoch: 4 [6000/60000 (10%)]\tLoss: 0.117371\n",
      "Train Epoch: 4 [8000/60000 (13%)]\tLoss: 0.092204\n",
      "Train Epoch: 4 [10000/60000 (17%)]\tLoss: 0.132524\n",
      "Train Epoch: 4 [12000/60000 (20%)]\tLoss: 0.107518\n",
      "Train Epoch: 4 [14000/60000 (23%)]\tLoss: 0.088634\n",
      "Train Epoch: 4 [16000/60000 (27%)]\tLoss: 0.086275\n",
      "Train Epoch: 4 [18000/60000 (30%)]\tLoss: 0.068791\n",
      "Train Epoch: 4 [20000/60000 (33%)]\tLoss: 0.100303\n",
      "Train Epoch: 4 [22000/60000 (37%)]\tLoss: 0.048131\n",
      "Train Epoch: 4 [24000/60000 (40%)]\tLoss: 0.046855\n",
      "Train Epoch: 4 [26000/60000 (43%)]\tLoss: 0.100617\n",
      "Train Epoch: 4 [28000/60000 (47%)]\tLoss: 0.113907\n",
      "Train Epoch: 4 [30000/60000 (50%)]\tLoss: 0.105930\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.072316\n",
      "Train Epoch: 4 [34000/60000 (57%)]\tLoss: 0.076757\n",
      "Train Epoch: 4 [36000/60000 (60%)]\tLoss: 0.045659\n",
      "Train Epoch: 4 [38000/60000 (63%)]\tLoss: 0.110426\n",
      "Train Epoch: 4 [40000/60000 (67%)]\tLoss: 0.094362\n",
      "Train Epoch: 4 [42000/60000 (70%)]\tLoss: 0.089497\n",
      "Train Epoch: 4 [44000/60000 (73%)]\tLoss: 0.075231\n",
      "Train Epoch: 4 [46000/60000 (77%)]\tLoss: 0.089082\n",
      "Train Epoch: 4 [48000/60000 (80%)]\tLoss: 0.088171\n",
      "Train Epoch: 4 [50000/60000 (83%)]\tLoss: 0.189555\n",
      "Train Epoch: 4 [52000/60000 (87%)]\tLoss: 0.074816\n",
      "Train Epoch: 4 [54000/60000 (90%)]\tLoss: 0.109351\n",
      "Train Epoch: 4 [56000/60000 (93%)]\tLoss: 0.136587\n",
      "Train Epoch: 4 [58000/60000 (97%)]\tLoss: 0.091750\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.049324\n",
      "Train Epoch: 5 [2000/60000 (3%)]\tLoss: 0.038569\n",
      "Train Epoch: 5 [4000/60000 (7%)]\tLoss: 0.041650\n",
      "Train Epoch: 5 [6000/60000 (10%)]\tLoss: 0.032117\n",
      "Train Epoch: 5 [8000/60000 (13%)]\tLoss: 0.054102\n",
      "Train Epoch: 5 [10000/60000 (17%)]\tLoss: 0.061938\n",
      "Train Epoch: 5 [12000/60000 (20%)]\tLoss: 0.077079\n",
      "Train Epoch: 5 [14000/60000 (23%)]\tLoss: 0.064644\n",
      "Train Epoch: 5 [16000/60000 (27%)]\tLoss: 0.056037\n",
      "Train Epoch: 5 [18000/60000 (30%)]\tLoss: 0.071157\n",
      "Train Epoch: 5 [20000/60000 (33%)]\tLoss: 0.056743\n",
      "Train Epoch: 5 [22000/60000 (37%)]\tLoss: 0.048749\n",
      "Train Epoch: 5 [24000/60000 (40%)]\tLoss: 0.116548\n",
      "Train Epoch: 5 [26000/60000 (43%)]\tLoss: 0.090786\n",
      "Train Epoch: 5 [28000/60000 (47%)]\tLoss: 0.035981\n",
      "Train Epoch: 5 [30000/60000 (50%)]\tLoss: 0.058747\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.085262\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 5 [34000/60000 (57%)]\tLoss: 0.088895\n",
      "Train Epoch: 5 [36000/60000 (60%)]\tLoss: 0.067811\n",
      "Train Epoch: 5 [38000/60000 (63%)]\tLoss: 0.027500\n",
      "Train Epoch: 5 [40000/60000 (67%)]\tLoss: 0.040862\n",
      "Train Epoch: 5 [42000/60000 (70%)]\tLoss: 0.041146\n",
      "Train Epoch: 5 [44000/60000 (73%)]\tLoss: 0.073849\n",
      "Train Epoch: 5 [46000/60000 (77%)]\tLoss: 0.081488\n",
      "Train Epoch: 5 [48000/60000 (80%)]\tLoss: 0.107836\n",
      "Train Epoch: 5 [50000/60000 (83%)]\tLoss: 0.081530\n",
      "Train Epoch: 5 [52000/60000 (87%)]\tLoss: 0.043836\n",
      "Train Epoch: 5 [54000/60000 (90%)]\tLoss: 0.178976\n",
      "Train Epoch: 5 [56000/60000 (93%)]\tLoss: 0.083735\n",
      "Train Epoch: 5 [58000/60000 (97%)]\tLoss: 0.074527\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.033737\n",
      "Train Epoch: 6 [2000/60000 (3%)]\tLoss: 0.066446\n",
      "Train Epoch: 6 [4000/60000 (7%)]\tLoss: 0.053485\n",
      "Train Epoch: 6 [6000/60000 (10%)]\tLoss: 0.047975\n",
      "Train Epoch: 6 [8000/60000 (13%)]\tLoss: 0.050934\n",
      "Train Epoch: 6 [10000/60000 (17%)]\tLoss: 0.110954\n",
      "Train Epoch: 6 [12000/60000 (20%)]\tLoss: 0.040699\n",
      "Train Epoch: 6 [14000/60000 (23%)]\tLoss: 0.064215\n",
      "Train Epoch: 6 [16000/60000 (27%)]\tLoss: 0.117808\n",
      "Train Epoch: 6 [18000/60000 (30%)]\tLoss: 0.055145\n",
      "Train Epoch: 6 [20000/60000 (33%)]\tLoss: 0.087167\n",
      "Train Epoch: 6 [22000/60000 (37%)]\tLoss: 0.056103\n",
      "Train Epoch: 6 [24000/60000 (40%)]\tLoss: 0.069373\n",
      "Train Epoch: 6 [26000/60000 (43%)]\tLoss: 0.053601\n",
      "Train Epoch: 6 [28000/60000 (47%)]\tLoss: 0.064693\n",
      "Train Epoch: 6 [30000/60000 (50%)]\tLoss: 0.055773\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.038650\n",
      "Train Epoch: 6 [34000/60000 (57%)]\tLoss: 0.045309\n",
      "Train Epoch: 6 [36000/60000 (60%)]\tLoss: 0.071815\n",
      "Train Epoch: 6 [38000/60000 (63%)]\tLoss: 0.042473\n",
      "Train Epoch: 6 [40000/60000 (67%)]\tLoss: 0.051961\n",
      "Train Epoch: 6 [42000/60000 (70%)]\tLoss: 0.146725\n",
      "Train Epoch: 6 [44000/60000 (73%)]\tLoss: 0.068288\n",
      "Train Epoch: 6 [46000/60000 (77%)]\tLoss: 0.055112\n",
      "Train Epoch: 6 [48000/60000 (80%)]\tLoss: 0.067407\n",
      "Train Epoch: 6 [50000/60000 (83%)]\tLoss: 0.034578\n",
      "Train Epoch: 6 [52000/60000 (87%)]\tLoss: 0.071298\n",
      "Train Epoch: 6 [54000/60000 (90%)]\tLoss: 0.056519\n",
      "Train Epoch: 6 [56000/60000 (93%)]\tLoss: 0.039147\n",
      "Train Epoch: 6 [58000/60000 (97%)]\tLoss: 0.040395\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.055734\n",
      "Train Epoch: 7 [2000/60000 (3%)]\tLoss: 0.037034\n",
      "Train Epoch: 7 [4000/60000 (7%)]\tLoss: 0.044899\n",
      "Train Epoch: 7 [6000/60000 (10%)]\tLoss: 0.039399\n",
      "Train Epoch: 7 [8000/60000 (13%)]\tLoss: 0.022788\n",
      "Train Epoch: 7 [10000/60000 (17%)]\tLoss: 0.026742\n",
      "Train Epoch: 7 [12000/60000 (20%)]\tLoss: 0.064920\n",
      "Train Epoch: 7 [14000/60000 (23%)]\tLoss: 0.045698\n",
      "Train Epoch: 7 [16000/60000 (27%)]\tLoss: 0.032298\n",
      "Train Epoch: 7 [18000/60000 (30%)]\tLoss: 0.034013\n",
      "Train Epoch: 7 [20000/60000 (33%)]\tLoss: 0.076380\n",
      "Train Epoch: 7 [22000/60000 (37%)]\tLoss: 0.064672\n",
      "Train Epoch: 7 [24000/60000 (40%)]\tLoss: 0.086797\n",
      "Train Epoch: 7 [26000/60000 (43%)]\tLoss: 0.040259\n",
      "Train Epoch: 7 [28000/60000 (47%)]\tLoss: 0.023909\n",
      "Train Epoch: 7 [30000/60000 (50%)]\tLoss: 0.040586\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.034235\n",
      "Train Epoch: 7 [34000/60000 (57%)]\tLoss: 0.038244\n",
      "Train Epoch: 7 [36000/60000 (60%)]\tLoss: 0.055427\n",
      "Train Epoch: 7 [38000/60000 (63%)]\tLoss: 0.084460\n",
      "Train Epoch: 7 [40000/60000 (67%)]\tLoss: 0.047940\n",
      "Train Epoch: 7 [42000/60000 (70%)]\tLoss: 0.035697\n",
      "Train Epoch: 7 [44000/60000 (73%)]\tLoss: 0.060332\n",
      "Train Epoch: 7 [46000/60000 (77%)]\tLoss: 0.074123\n",
      "Train Epoch: 7 [48000/60000 (80%)]\tLoss: 0.072797\n",
      "Train Epoch: 7 [50000/60000 (83%)]\tLoss: 0.070056\n",
      "Train Epoch: 7 [52000/60000 (87%)]\tLoss: 0.027587\n",
      "Train Epoch: 7 [54000/60000 (90%)]\tLoss: 0.051325\n",
      "Train Epoch: 7 [56000/60000 (93%)]\tLoss: 0.055888\n",
      "Train Epoch: 7 [58000/60000 (97%)]\tLoss: 0.089383\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.029684\n",
      "Train Epoch: 8 [2000/60000 (3%)]\tLoss: 0.026496\n",
      "Train Epoch: 8 [4000/60000 (7%)]\tLoss: 0.025663\n",
      "Train Epoch: 8 [6000/60000 (10%)]\tLoss: 0.053772\n",
      "Train Epoch: 8 [8000/60000 (13%)]\tLoss: 0.029012\n",
      "Train Epoch: 8 [10000/60000 (17%)]\tLoss: 0.041398\n",
      "Train Epoch: 8 [12000/60000 (20%)]\tLoss: 0.055126\n",
      "Train Epoch: 8 [14000/60000 (23%)]\tLoss: 0.029140\n",
      "Train Epoch: 8 [16000/60000 (27%)]\tLoss: 0.047951\n",
      "Train Epoch: 8 [18000/60000 (30%)]\tLoss: 0.030890\n",
      "Train Epoch: 8 [20000/60000 (33%)]\tLoss: 0.043033\n",
      "Train Epoch: 8 [22000/60000 (37%)]\tLoss: 0.040108\n",
      "Train Epoch: 8 [24000/60000 (40%)]\tLoss: 0.025543\n",
      "Train Epoch: 8 [26000/60000 (43%)]\tLoss: 0.046169\n",
      "Train Epoch: 8 [28000/60000 (47%)]\tLoss: 0.026681\n",
      "Train Epoch: 8 [30000/60000 (50%)]\tLoss: 0.031184\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.032795\n",
      "Train Epoch: 8 [34000/60000 (57%)]\tLoss: 0.060292\n",
      "Train Epoch: 8 [36000/60000 (60%)]\tLoss: 0.031390\n",
      "Train Epoch: 8 [38000/60000 (63%)]\tLoss: 0.072799\n",
      "Train Epoch: 8 [40000/60000 (67%)]\tLoss: 0.023399\n",
      "Train Epoch: 8 [42000/60000 (70%)]\tLoss: 0.057086\n",
      "Train Epoch: 8 [44000/60000 (73%)]\tLoss: 0.032841\n",
      "Train Epoch: 8 [46000/60000 (77%)]\tLoss: 0.025558\n",
      "Train Epoch: 8 [48000/60000 (80%)]\tLoss: 0.096944\n",
      "Train Epoch: 8 [50000/60000 (83%)]\tLoss: 0.062940\n",
      "Train Epoch: 8 [52000/60000 (87%)]\tLoss: 0.040955\n",
      "Train Epoch: 8 [54000/60000 (90%)]\tLoss: 0.042536\n",
      "Train Epoch: 8 [56000/60000 (93%)]\tLoss: 0.028835\n",
      "Train Epoch: 8 [58000/60000 (97%)]\tLoss: 0.081329\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.042771\n",
      "Train Epoch: 9 [2000/60000 (3%)]\tLoss: 0.069507\n",
      "Train Epoch: 9 [4000/60000 (7%)]\tLoss: 0.033446\n",
      "Train Epoch: 9 [6000/60000 (10%)]\tLoss: 0.015779\n",
      "Train Epoch: 9 [8000/60000 (13%)]\tLoss: 0.045163\n",
      "Train Epoch: 9 [10000/60000 (17%)]\tLoss: 0.046324\n",
      "Train Epoch: 9 [12000/60000 (20%)]\tLoss: 0.046970\n",
      "Train Epoch: 9 [14000/60000 (23%)]\tLoss: 0.024310\n",
      "Train Epoch: 9 [16000/60000 (27%)]\tLoss: 0.044924\n",
      "Train Epoch: 9 [18000/60000 (30%)]\tLoss: 0.027348\n",
      "Train Epoch: 9 [20000/60000 (33%)]\tLoss: 0.024046\n",
      "Train Epoch: 9 [22000/60000 (37%)]\tLoss: 0.144604\n",
      "Train Epoch: 9 [24000/60000 (40%)]\tLoss: 0.030108\n",
      "Train Epoch: 9 [26000/60000 (43%)]\tLoss: 0.036319\n",
      "Train Epoch: 9 [28000/60000 (47%)]\tLoss: 0.012322\n",
      "Train Epoch: 9 [30000/60000 (50%)]\tLoss: 0.045116\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.040549\n",
      "Train Epoch: 9 [34000/60000 (57%)]\tLoss: 0.031982\n",
      "Train Epoch: 9 [36000/60000 (60%)]\tLoss: 0.024043\n",
      "Train Epoch: 9 [38000/60000 (63%)]\tLoss: 0.048349\n",
      "Train Epoch: 9 [40000/60000 (67%)]\tLoss: 0.020627\n",
      "Train Epoch: 9 [42000/60000 (70%)]\tLoss: 0.053083\n",
      "Train Epoch: 9 [44000/60000 (73%)]\tLoss: 0.033318\n",
      "Train Epoch: 9 [46000/60000 (77%)]\tLoss: 0.061507\n",
      "Train Epoch: 9 [48000/60000 (80%)]\tLoss: 0.048764\n",
      "Train Epoch: 9 [50000/60000 (83%)]\tLoss: 0.038881\n",
      "Train Epoch: 9 [52000/60000 (87%)]\tLoss: 0.023094\n",
      "Train Epoch: 9 [54000/60000 (90%)]\tLoss: 0.047967\n",
      "Train Epoch: 9 [56000/60000 (93%)]\tLoss: 0.013707\n",
      "Train Epoch: 9 [58000/60000 (97%)]\tLoss: 0.023093\n"
     ]
    }
   ],
   "source": [
    "learning_rate=0.01\n",
    "epochs=10\n",
    "batch_size=200\n",
    "log_interval=10\n",
    "optimizer = optim.SGD(fcn_i1.parameters(), lr=learning_rate, momentum=0.9)\n",
    "\n",
    "criterion = nn.NLLLoss()\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('../data', train=True, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ])),\n",
    "        batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])),\n",
    "        batch_size=batch_size, shuffle=True)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "        for batch_idx, (data, target) in enumerate(train_loader):\n",
    "            data, target = Variable(data), Variable(target)\n",
    "            # resize data from (batch_size, 1, 28, 28) to (batch_size, 28*28)\n",
    "            data = data.view(-1, 28*28)\n",
    "            optimizer.zero_grad()\n",
    "            net_out = fcn_i1(data)\n",
    "            loss = criterion(net_out, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if batch_idx % log_interval == 0:\n",
    "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                    epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                           100. * batch_idx / len(train_loader), loss.data[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kushal/anaconda3/envs/ece587_ptc/lib/python3.6/site-packages/ipykernel_launcher.py:16: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "-4.7455e+00 -2.4379e+00 -2.4407e-01  ...  -3.2788e+00 -4.2154e+00 -9.6741e+00\n",
      "-1.8482e+01 -1.4433e+01 -1.8767e+01  ...  -1.6971e+01 -1.0323e+01 -1.1692e+01\n",
      "-2.3150e+01 -2.0081e+01 -2.4693e+01  ...  -2.4956e+01 -1.6772e+01 -1.3901e+01\n",
      "                ...                   ⋱                   ...                \n",
      "-8.0633e+00 -7.1081e+00 -5.0214e+00  ...  -6.0652e-01 -8.5205e-01 -6.4841e+00\n",
      "-1.0275e+01 -1.3163e+01 -9.1954e+00  ...  -1.5243e+01 -1.6929e-03 -1.0964e+01\n",
      "-1.7412e-05 -2.1212e+01 -1.5227e+01  ...  -1.3484e+01 -1.9751e+01 -1.1867e+01\n",
      "[torch.FloatTensor of size 200x10]\n",
      "\n",
      "Variable containing:\n",
      "-1.2682e+01 -9.9191e+00 -1.3751e+01  ...  -2.2276e+01 -1.3498e-01 -1.6161e+01\n",
      "-1.0503e+01 -5.4907e+00 -7.8043e+00  ...  -1.3544e-02 -5.0245e+00 -7.1995e+00\n",
      "-1.5935e+01 -1.8277e+01 -1.4735e+01  ...  -2.1422e+01 -1.5230e+01 -2.3486e+01\n",
      "                ...                   ⋱                   ...                \n",
      "-3.7475e-06 -2.3317e+01 -1.3559e+01  ...  -1.9973e+01 -1.9771e+01 -1.6896e+01\n",
      "-1.9568e+01 -1.4629e+01 -1.5250e+01  ...  -1.9442e+01 -1.8967e+01 -1.7400e+01\n",
      "-1.9264e+01 -1.1217e+01 -2.0487e-05  ...  -1.2334e+01 -1.3430e+01 -2.2752e+01\n",
      "[torch.FloatTensor of size 200x10]\n",
      "\n",
      "Variable containing:\n",
      "-1.0482e+01 -1.1367e+01 -8.5529e+00  ...  -9.9014e+00 -1.5835e+01 -1.2638e+01\n",
      "-1.4852e+01 -8.9350e+00 -1.0533e+01  ...  -4.1551e-04 -1.1988e+01 -1.0190e+01\n",
      "-1.6083e+01 -1.4874e+01 -1.9132e+01  ...  -9.7270e+00 -1.0670e+01 -6.0637e-04\n",
      "                ...                   ⋱                   ...                \n",
      "-1.4264e+01 -1.2231e+01 -8.2085e+00  ...  -7.7762e-04 -1.5508e+01 -1.1016e+01\n",
      "-1.2817e+01 -8.5181e+00 -5.6822e+00  ...  -9.7917e+00 -9.2528e+00 -7.4352e+00\n",
      "-2.4169e-06 -2.1388e+01 -1.4752e+01  ...  -1.7719e+01 -1.7997e+01 -1.4424e+01\n",
      "[torch.FloatTensor of size 200x10]\n",
      "\n",
      "Variable containing:\n",
      "-1.3000e+01 -1.9265e+01 -2.2909e+01  ...  -1.9105e+01 -1.2592e+01 -7.6515e+00\n",
      "-1.9433e+01 -1.7798e+01 -1.6888e+01  ...  -9.7303e+00 -1.3379e+01 -8.2187e+00\n",
      "-1.9429e+01 -1.4797e+01 -1.6974e+01  ...  -2.1575e+01 -1.8651e+01 -2.9685e+01\n",
      "                ...                   ⋱                   ...                \n",
      "-1.9390e+01 -1.9619e-04 -1.3929e+01  ...  -9.1396e+00 -9.6138e+00 -1.4342e+01\n",
      "-1.0862e+01 -1.0685e+01 -5.7811e+00  ...  -1.2936e+01 -3.5337e-03 -1.1699e+01\n",
      "-1.6842e+01 -1.7979e+01 -1.5792e+01  ...  -2.5696e+01 -1.8300e+01 -2.5353e+01\n",
      "[torch.FloatTensor of size 200x10]\n",
      "\n",
      "Variable containing:\n",
      "-1.0370e+01 -9.6848e+00 -4.4218e-02  ...  -1.3627e+01 -4.7328e+00 -1.4833e+01\n",
      "-9.9232e+00 -1.1444e+01 -1.2099e+01  ...  -1.6410e+01 -9.0921e+00 -1.3578e+01\n",
      "-8.7899e+00 -2.7069e+00 -6.0607e+00  ...  -2.5233e+00 -9.2606e+00 -1.0275e+01\n",
      "                ...                   ⋱                   ...                \n",
      "-1.6174e+01 -1.7220e-04 -1.1320e+01  ...  -9.0184e+00 -1.2925e+01 -1.5386e+01\n",
      "-4.6156e+00 -8.6678e+00 -1.1769e+01  ...  -1.0378e+01 -7.4844e+00 -7.9820e+00\n",
      "-1.3510e+01 -1.9593e+01 -2.2565e+01  ...  -2.5947e+01 -1.7895e+01 -1.5380e+01\n",
      "[torch.FloatTensor of size 200x10]\n",
      "\n",
      "Variable containing:\n",
      "-1.6553e+01 -1.1684e+01 -8.4567e+00  ...  -2.5212e-04 -1.5325e+01 -1.6849e+01\n",
      "-1.9264e+01 -8.9103e+00 -1.5032e-04  ...  -1.2487e+01 -1.3093e+01 -2.4417e+01\n",
      "-1.4451e+01 -1.8123e+01 -1.1878e+01  ...  -3.4127e-05 -1.4408e+01 -1.0581e+01\n",
      "                ...                   ⋱                   ...                \n",
      "-6.0643e-03 -1.9307e+01 -9.5534e+00  ...  -1.8080e+01 -1.1666e+01 -1.8356e+01\n",
      "-3.3068e+01 -2.1299e+01 -2.5685e+01  ...  -2.8567e+01 -2.5707e+01 -2.6556e+01\n",
      "-1.0123e+01 -1.0379e+01 -3.6593e+00  ...  -1.5240e+01 -8.0214e+00 -1.7294e+01\n",
      "[torch.FloatTensor of size 200x10]\n",
      "\n",
      "Variable containing:\n",
      "-1.2188e-03 -2.3410e+01 -1.0554e+01  ...  -1.0998e+01 -1.4147e+01 -6.7522e+00\n",
      "-2.4685e+01 -2.1664e+01 -2.3354e+01  ...  -3.2353e+01 -1.8816e+01 -2.1517e+01\n",
      "-9.5606e+00 -1.2696e+01 -1.0113e+01  ...  -5.4820e+00 -8.7477e+00 -3.1257e+00\n",
      "                ...                   ⋱                   ...                \n",
      "-1.7444e+01 -2.1813e+01 -2.2218e+01  ...  -1.2724e+01 -1.0664e+01 -5.8979e-05\n",
      "-5.6866e+00 -1.7611e+01 -9.8711e+00  ...  -5.5399e+00 -6.0607e+00 -1.1745e-02\n",
      "-1.1143e+01 -1.7558e+01 -1.6097e+01  ...  -1.3571e-03 -1.7345e+01 -6.7846e+00\n",
      "[torch.FloatTensor of size 200x10]\n",
      "\n",
      "Variable containing:\n",
      "-1.8470e+01 -9.4209e-05 -1.0804e+01  ...  -9.6228e+00 -1.2944e+01 -1.7976e+01\n",
      "-1.5792e+01 -2.2764e+01 -1.7726e+01  ...  -8.2041e+00 -1.1754e+01 -2.8431e-04\n",
      "-5.1235e-02 -1.4635e+01 -9.5944e+00  ...  -6.3731e+00 -1.3420e+01 -8.0708e+00\n",
      "                ...                   ⋱                   ...                \n",
      "-1.3907e+01 -1.1909e+01 -1.6869e+01  ...  -9.1988e+00 -1.1412e+01 -8.2183e+00\n",
      "-1.6306e+01 -1.3346e+01 -1.9149e+01  ...  -8.3165e+00 -9.9147e+00 -5.3748e-04\n",
      "-1.0969e+01 -1.9207e+01 -9.7676e+00  ...  -1.8674e+01 -1.5259e+01 -1.8192e+01\n",
      "[torch.FloatTensor of size 200x10]\n",
      "\n",
      "Variable containing:\n",
      "-1.3788e+01 -7.3296e+00 -1.2678e+01  ...  -1.1392e+01 -1.4754e+01 -9.5266e+00\n",
      "-1.1217e+01 -1.3045e+01 -1.2680e+01  ...  -1.5380e+01 -8.7717e+00 -2.1133e+01\n",
      "-1.5627e+01 -2.6621e+01 -1.4729e+01  ...  -2.1037e+01 -2.1228e+01 -2.1913e+01\n",
      "                ...                   ⋱                   ...                \n",
      "-1.7164e+01 -1.5757e+01 -5.1187e-05  ...  -1.2079e+01 -1.9770e+01 -2.3744e+01\n",
      "-1.6457e+01 -7.0755e-04 -1.2167e+01  ...  -9.0298e+00 -8.8690e+00 -9.6287e+00\n",
      "-2.3142e+01 -1.6810e+01 -1.9492e+01  ...  -2.7601e+01 -1.8036e+01 -1.7194e+01\n",
      "[torch.FloatTensor of size 200x10]\n",
      "\n",
      "Variable containing:\n",
      "-7.8738e-04 -1.7003e+01 -7.2000e+00  ...  -1.6130e+01 -1.4229e+01 -1.2201e+01\n",
      "-2.0017e+01 -1.8300e+01 -1.1413e+01  ...  -1.1009e+01 -1.6575e+01 -1.6418e+01\n",
      "-2.0483e+01 -1.5850e+01 -1.0455e+01  ...  -8.6478e-04 -1.7994e+01 -1.4372e+01\n",
      "                ...                   ⋱                   ...                \n",
      "-1.8477e+01 -1.9573e+01 -2.1225e+01  ...  -2.2218e+01 -1.5200e+01 -1.0190e+01\n",
      "-1.7877e+01 -2.1940e+01 -1.8994e+01  ...  -1.1234e+01 -1.2413e+01 -2.6268e-05\n",
      "-4.1981e-05 -2.2633e+01 -1.4013e+01  ...  -1.4010e+01 -1.8296e+01 -1.2210e+01\n",
      "[torch.FloatTensor of size 200x10]\n",
      "\n",
      "Variable containing:\n",
      "-4.9872e+00 -9.7941e+00 -1.0757e+01  ...  -1.2759e+01 -9.5195e+00 -1.0166e+01\n",
      "-2.0907e+01 -1.6081e+01 -9.9478e-07  ...  -1.4759e+01 -1.8965e+01 -2.6843e+01\n",
      "-1.8658e+01 -1.7649e+01 -1.3698e+01  ...  -1.8976e+01 -7.8834e-06 -1.3448e+01\n",
      "                ...                   ⋱                   ...                \n",
      "-1.5014e+01 -1.4410e+01 -1.2258e+01  ...  -1.3917e+01 -4.7888e-04 -1.1516e+01\n",
      "-1.4893e+01 -1.2618e+01 -1.7908e+01  ...  -1.8863e+01 -1.2418e+01 -8.6117e+00\n",
      "-1.4889e+01 -7.1355e+00 -1.0284e+01  ...  -1.0604e+01 -3.2513e-03 -9.1656e+00\n",
      "[torch.FloatTensor of size 200x10]\n",
      "\n",
      "Variable containing:\n",
      "-1.6539e+01 -1.1104e+01 -1.1143e+01  ...  -5.0727e+00 -2.8815e+00 -9.2835e-02\n",
      "-1.0872e+01 -1.2760e+01 -1.1506e+01  ...  -9.3795e+00 -1.0296e+01 -7.2151e-02\n",
      "-2.0281e+01 -1.2677e+01 -1.8716e+01  ...  -1.2491e+01 -1.3437e+01 -9.0167e+00\n",
      "                ...                   ⋱                   ...                \n",
      "-1.8223e+01 -2.5001e+01 -2.0143e+01  ...  -1.1096e+01 -1.3230e+01 -2.1030e-05\n",
      "-2.8736e+01 -2.3084e+01 -2.2347e+01  ...  -2.0554e+01 -1.9331e+01 -1.4575e+01\n",
      "-1.1341e+01 -1.0333e+01 -1.2560e+01  ...  -1.1590e+01 -1.3108e+01 -1.4285e+01\n",
      "[torch.FloatTensor of size 200x10]\n",
      "\n",
      "Variable containing:\n",
      "-1.5763e+01 -1.3158e+01 -8.5258e+00  ...  -7.2366e-04 -1.4030e+01 -1.0921e+01\n",
      "-1.2804e-03 -1.4185e+01 -8.1203e+00  ...  -8.5103e+00 -9.0646e+00 -1.0383e+01\n",
      "-1.7288e+01 -2.0341e-05 -1.1415e+01  ...  -1.2301e+01 -1.3049e+01 -2.0112e+01\n",
      "                ...                   ⋱                   ...                \n",
      "-1.0589e+01 -1.4517e+01 -3.4973e+00  ...  -1.3880e+01 -1.4003e+01 -1.8059e+01\n",
      "-2.1029e+01 -1.5534e+01 -1.4488e+01  ...  -1.6029e+01 -1.8790e+01 -1.6501e+01\n",
      "-1.2156e+01 -1.8021e+01 -1.3648e+01  ...  -1.9183e+01 -1.5230e+01 -1.6339e+01\n",
      "[torch.FloatTensor of size 200x10]\n",
      "\n",
      "Variable containing:\n",
      "-1.6581e+01 -2.3873e+01 -1.5356e+01  ...  -1.9463e+01 -9.2173e-05 -1.0000e+01\n",
      "-1.7049e+01 -1.4800e-03 -1.2912e+01  ...  -9.4668e+00 -7.2833e+00 -1.3347e+01\n",
      "-1.9665e+01 -2.2045e+01 -2.1515e+01  ...  -1.5487e+01 -1.1977e+01 -2.0579e-04\n",
      "                ...                   ⋱                   ...                \n",
      "-1.8295e+01 -1.3248e+01 -9.3169e-06  ...  -1.5456e+01 -1.9736e+01 -2.9476e+01\n",
      "-9.8911e+00 -2.3188e-03 -6.8276e+00  ...  -9.0618e+00 -6.9171e+00 -1.3683e+01\n",
      "-2.6740e+01 -1.1913e+01 -8.3854e-05  ...  -1.8386e+01 -1.6473e+01 -2.9430e+01\n",
      "[torch.FloatTensor of size 200x10]\n",
      "\n",
      "Variable containing:\n",
      "-1.5599e+01 -1.8980e+01 -1.0616e+01  ...  -1.8233e+01 -3.0321e-04 -1.0950e+01\n",
      "-2.1667e+01 -2.5143e+01 -1.8745e+01  ...  -1.9084e+01 -2.4641e+01 -1.8252e+01\n",
      "-1.2237e+01 -1.2307e+01 -9.1174e+00  ...  -1.0732e+01 -5.9450e-01 -1.2138e+01\n",
      "                ...                   ⋱                   ...                \n",
      "-1.9307e+01 -1.3842e+01 -1.1669e+01  ...  -1.3585e+01 -1.3123e+01 -8.5932e+00\n",
      "-1.9194e+01 -1.2995e+01 -1.1541e+01  ...  -1.8364e+01 -1.0432e+01 -1.2101e+01\n",
      "-1.7713e+01 -1.1754e-03 -1.1111e+01  ...  -6.7947e+00 -1.3033e+01 -1.4484e+01\n",
      "[torch.FloatTensor of size 200x10]\n",
      "\n",
      "Variable containing:\n",
      "-1.6523e+01 -1.9633e+01 -1.9373e+01  ...  -1.9453e+01 -1.9794e+01 -1.0677e+01\n",
      "-1.5286e+01 -2.0164e+01 -1.3670e+01  ...  -2.4705e+01 -1.5926e+01 -2.1908e+01\n",
      "-1.0551e-01 -1.0599e+01 -2.5275e+00  ...  -8.0275e+00 -7.9582e+00 -4.0544e+00\n",
      "                ...                   ⋱                   ...                \n",
      "-1.0077e+01 -1.4485e+01 -1.9494e+01  ...  -2.0619e+01 -1.6529e+01 -9.3262e+00\n",
      "-1.5544e+01 -1.2266e+01 -1.5787e+01  ...  -1.2710e+01 -1.2545e+01 -1.6857e+01\n",
      "-1.4690e+01 -1.7783e+01 -1.4082e+01  ...  -1.8971e+01 -1.9539e+01 -2.3944e+01\n",
      "[torch.FloatTensor of size 200x10]\n",
      "\n",
      "Variable containing:\n",
      "-1.1467e+01 -9.3081e+00 -8.3437e+00  ...  -1.5788e-03 -1.3313e+01 -7.5144e+00\n",
      "-1.4883e+01 -1.7115e+01 -2.0936e-04  ...  -1.7158e+01 -1.8689e+01 -2.0909e+01\n",
      "-1.1783e+01 -1.2871e+01 -9.0112e+00  ...  -8.4188e+00 -1.2496e+01 -7.4076e+00\n",
      "                ...                   ⋱                   ...                \n",
      "-1.8695e+01 -2.3652e-04 -1.3405e+01  ...  -8.4833e+00 -1.2413e+01 -1.5105e+01\n",
      "-1.9180e+01 -1.6558e+01 -2.2133e+01  ...  -2.0734e+01 -1.5304e+01 -1.4555e+01\n",
      "-1.9179e+01 -1.8601e+01 -7.0156e+00  ...  -1.3855e+01 -1.5250e+01 -2.4105e+01\n",
      "[torch.FloatTensor of size 200x10]\n",
      "\n",
      "Variable containing:\n",
      "-1.3599e+01 -1.3905e+01 -1.3336e+01  ...  -8.1357e+00 -9.5267e+00 -1.2109e-03\n",
      "-1.9469e+01 -2.2379e+01 -1.3500e+01  ...  -2.7338e+01 -1.9907e-06 -1.9615e+01\n",
      "-9.8009e+00 -1.0628e+01 -8.5261e+00  ...  -1.2754e+01 -8.7032e+00 -1.5297e+01\n",
      "                ...                   ⋱                   ...                \n",
      "-1.4345e+01 -1.4797e+01 -1.1444e+01  ...  -1.8647e+01 -1.5027e-04 -1.4237e+01\n",
      "-1.3023e+01 -1.2937e+01 -1.1623e+01  ...  -7.9940e+00 -1.1956e+01 -5.5097e+00\n",
      "-1.4536e+01 -1.0665e+01 -8.8669e+00  ...  -3.4879e-03 -1.3596e+01 -6.2953e+00\n",
      "[torch.FloatTensor of size 200x10]\n",
      "\n",
      "Variable containing:\n",
      "-1.1447e+01 -1.2242e+01 -1.0929e+01  ...  -1.8555e+01 -7.8720e+00 -1.8375e+01\n",
      "-6.8911e+00 -1.1960e+01 -8.4346e+00  ...  -1.3859e+01 -2.9027e-02 -7.3501e+00\n",
      "-1.3340e+01 -5.3230e-04 -1.3278e+01  ...  -7.8059e+00 -9.5727e+00 -1.3736e+01\n",
      "                ...                   ⋱                   ...                \n",
      "-1.7282e+01 -1.6792e+01 -2.2033e+01  ...  -2.4939e+01 -1.4677e+01 -1.1794e+01\n",
      "-1.0197e+01 -8.5165e+00 -7.4184e-04  ...  -8.0533e+00 -8.8872e+00 -1.3009e+01\n",
      "-1.2279e+01 -1.2347e+01 -1.1912e+01  ...  -3.2292e-04 -1.4312e+01 -8.1419e+00\n",
      "[torch.FloatTensor of size 200x10]\n",
      "\n",
      "Variable containing:\n",
      "-9.5908e+00 -4.9777e+00 -8.1385e+00  ...  -4.6511e-02 -8.4100e+00 -4.6169e+00\n",
      "-1.7856e+01 -7.6344e+00 -1.6876e-03  ...  -1.9364e+01 -1.2719e+01 -2.6108e+01\n",
      "-1.8170e+01 -1.8004e+01 -1.3707e+01  ...  -1.7689e+01 -9.6758e+00 -1.2766e+01\n",
      "                ...                   ⋱                   ...                \n",
      "-1.5348e+01 -9.5709e+00 -1.3612e+01  ...  -1.9555e+01 -8.3977e+00 -9.0004e+00\n",
      "-1.2507e+01 -1.1561e-03 -9.3282e+00  ...  -9.1354e+00 -8.3361e+00 -1.8903e+01\n",
      "-1.9456e+01 -1.2717e-03 -8.1908e+00  ...  -1.2942e+01 -9.7437e+00 -1.8307e+01\n",
      "[torch.FloatTensor of size 200x10]\n",
      "\n",
      "Variable containing:\n",
      "-1.7318e+01 -2.4128e+01 -1.4904e+01  ...  -1.3402e+01 -1.0216e+01 -1.3221e+01\n",
      "-4.9939e-05 -2.2779e+01 -1.3308e+01  ...  -1.2967e+01 -1.7439e+01 -1.0018e+01\n",
      "-1.0517e+01 -1.2524e+01 -1.1986e+01  ...  -1.8646e+01 -2.9327e-03 -1.3289e+01\n",
      "                ...                   ⋱                   ...                \n",
      "-1.1544e+01 -6.0221e+00 -1.4650e+01  ...  -1.6022e+01 -8.9769e+00 -6.5049e+00\n",
      "-1.2407e+01 -1.2153e+01 -1.0372e+01  ...  -1.1383e+01 -8.3989e+00 -1.1338e+01\n",
      "-1.6264e+01 -3.4821e-05 -1.1019e+01  ...  -1.2123e+01 -1.1411e+01 -1.8597e+01\n",
      "[torch.FloatTensor of size 200x10]\n",
      "\n",
      "Variable containing:\n",
      "-1.4997e+01 -1.8776e+01 -1.2643e+01  ...  -1.2865e+01 -1.1785e+01 -1.7831e-03\n",
      "-1.6442e+01 -2.6150e+01 -2.1452e+01  ...  -2.4596e+01 -1.7282e+01 -2.8227e+01\n",
      "-1.6452e+01 -1.0411e-03 -1.2123e+01  ...  -7.4982e+00 -8.3606e+00 -9.2293e+00\n",
      "                ...                   ⋱                   ...                \n",
      "-4.0841e-07 -2.4179e+01 -1.5877e+01  ...  -1.9055e+01 -2.2685e+01 -1.5199e+01\n",
      "-1.7145e+01 -2.0679e+01 -1.3323e+01  ...  -1.7071e+01 -6.8285e-04 -7.8380e+00\n",
      "-9.1670e+00 -1.7117e+01 -1.3776e+01  ...  -4.2838e+00 -1.0071e+01 -1.4832e-02\n",
      "[torch.FloatTensor of size 200x10]\n",
      "\n",
      "Variable containing:\n",
      "-1.7083e+01 -1.0043e+01 -8.8901e+00  ...  -2.8449e-04 -1.1842e+01 -1.3699e+01\n",
      "-1.9230e+01 -1.7646e+01 -1.0530e+01  ...  -5.5583e-05 -1.6828e+01 -1.6036e+01\n",
      "-1.2079e+01 -1.8570e+01 -9.0358e+00  ...  -1.2503e+01 -1.5059e-03 -6.6317e+00\n",
      "                ...                   ⋱                   ...                \n",
      "-1.2376e+01 -1.5764e+01 -1.6956e+01  ...  -2.2943e-04 -2.0971e+01 -8.5339e+00\n",
      "-6.4257e+00 -1.0257e+01 -5.3606e+00  ...  -1.7510e+01 -8.5992e+00 -1.3774e+01\n",
      "-1.5279e+01 -1.8044e-03 -1.0714e+01  ...  -6.5462e+00 -8.5579e+00 -1.0015e+01\n",
      "[torch.FloatTensor of size 200x10]\n",
      "\n",
      "Variable containing:\n",
      "-1.9246e-04 -1.7564e+01 -1.3326e+01  ...  -1.5533e+01 -1.0418e+01 -1.4272e+01\n",
      "-6.1342e-04 -2.2342e+01 -7.4078e+00  ...  -1.8384e+01 -1.3843e+01 -1.3035e+01\n",
      "-1.6221e+01 -6.7268e+00 -1.9671e-03  ...  -1.0696e+01 -7.2596e+00 -1.6210e+01\n",
      "                ...                   ⋱                   ...                \n",
      "-6.8427e+00 -8.5968e+00 -5.7222e-01  ...  -6.4319e+00 -8.8438e+00 -1.1487e+01\n",
      "-1.7511e+01 -1.6258e+01 -1.4093e+01  ...  -1.1241e+01 -1.6611e+01 -1.2732e+01\n",
      "-1.8158e+01 -2.0788e-04 -1.4298e+01  ...  -8.6408e+00 -1.3751e+01 -1.4532e+01\n",
      "[torch.FloatTensor of size 200x10]\n",
      "\n",
      "Variable containing:\n",
      "-1.7534e+01 -1.0412e+01 -1.4698e+01  ...  -2.0353e+01 -1.6829e+01 -1.7559e+01\n",
      "-1.7878e+01 -4.7243e-04 -1.2468e+01  ...  -8.1653e+00 -9.6751e+00 -1.0499e+01\n",
      "-9.6384e+00 -1.4775e+01 -1.0591e+01  ...  -9.7524e+00 -9.4699e+00 -1.4196e+01\n",
      "                ...                   ⋱                   ...                \n",
      "-1.7176e+01 -1.8783e-04 -1.0297e+01  ...  -8.8877e+00 -1.2327e+01 -1.6488e+01\n",
      "-1.6539e-04 -1.9911e+01 -1.2990e+01  ...  -1.0573e+01 -1.4509e+01 -9.0084e+00\n",
      "-1.0593e+01 -9.0917e+00 -1.2564e+01  ...  -1.0488e+01 -1.5027e+01 -1.0150e+01\n",
      "[torch.FloatTensor of size 200x10]\n",
      "\n",
      "Variable containing:\n",
      "-5.0828e+00 -8.4404e+00 -1.1481e+01  ...  -1.4766e+01 -5.6911e-01 -4.3384e+00\n",
      "-1.9649e+01 -1.2292e+01 -1.2191e-05  ...  -1.5599e+01 -1.4734e+01 -1.9422e+01\n",
      "-2.1879e+01 -1.9342e+01 -2.3558e+01  ...  -2.8911e+01 -1.8086e+01 -1.6094e+01\n",
      "                ...                   ⋱                   ...                \n",
      "-1.8058e+01 -2.0451e+01 -1.6549e+01  ...  -1.0894e+01 -1.3234e+01 -1.2097e-04\n",
      "-2.4471e-06 -2.5280e+01 -1.4004e+01  ...  -1.9581e+01 -2.1658e+01 -1.4143e+01\n",
      "-8.3961e+00 -1.3885e+01 -1.2557e+01  ...  -1.1638e+01 -6.6365e+00 -1.0820e+01\n",
      "[torch.FloatTensor of size 200x10]\n",
      "\n",
      "Variable containing:\n",
      "-4.3183e-04 -2.0713e+01 -1.1606e+01  ...  -1.6005e+01 -1.1608e+01 -1.4465e+01\n",
      "-1.2134e-03 -1.7509e+01 -7.0455e+00  ...  -1.2375e+01 -1.1658e+01 -1.0728e+01\n",
      "-1.3395e+01 -1.6789e+01 -1.4283e+01  ...  -8.7394e+00 -8.0518e+00 -9.2221e-04\n",
      "                ...                   ⋱                   ...                \n",
      "-1.5679e+01 -1.5705e+01 -1.5882e+01  ...  -1.1367e+01 -8.0909e+00 -5.3746e-04\n",
      "-3.4813e+00 -1.1997e+01 -7.2748e+00  ...  -4.5037e-02 -1.3172e+01 -9.8535e+00\n",
      "-6.7995e+00 -2.0720e+01 -1.5148e+01  ...  -2.1127e+01 -1.2185e-03 -9.4598e+00\n",
      "[torch.FloatTensor of size 200x10]\n",
      "\n",
      "Variable containing:\n",
      "-1.7158e+01 -2.0385e+01 -1.4179e+01  ...  -9.0096e-06 -2.1148e+01 -1.1707e+01\n",
      "-2.1344e+01 -1.8314e+01 -1.6783e+01  ...  -1.0773e+01 -1.7120e+01 -9.2360e+00\n",
      "-1.6297e+01 -1.1100e-03 -1.1252e+01  ...  -6.8919e+00 -1.0578e+01 -1.1679e+01\n",
      "                ...                   ⋱                   ...                \n",
      "-1.8711e+01 -1.2810e-04 -1.3800e+01  ...  -9.1350e+00 -1.1375e+01 -1.6021e+01\n",
      "-1.5316e+01 -1.8364e+01 -1.6580e+01  ...  -1.8581e+01 -1.3654e-06 -1.6918e+01\n",
      "-1.2263e+01 -1.2199e+01 -7.8528e+00  ...  -1.0677e+01 -1.1082e+01 -1.4069e+01\n",
      "[torch.FloatTensor of size 200x10]\n",
      "\n",
      "Variable containing:\n",
      "-2.7764e-06 -2.6535e+01 -1.3170e+01  ...  -1.9574e+01 -2.0132e+01 -1.4090e+01\n",
      "-1.0371e+01 -1.1385e+01 -8.2035e+00  ...  -1.0256e+01 -1.2685e+01 -1.4518e+01\n",
      "-1.0155e+01 -1.6567e+01 -1.0324e+01  ...  -1.8307e+01 -1.9336e-04 -1.4155e+01\n",
      "                ...                   ⋱                   ...                \n",
      "-1.4056e+01 -2.2453e-04 -1.0930e+01  ...  -9.5338e+00 -9.2751e+00 -1.6755e+01\n",
      "-1.5364e+01 -1.6389e+01 -1.7291e+01  ...  -9.9964e+00 -1.1287e+01 -3.5419e-04\n",
      "-2.0137e+01 -1.7337e+01 -1.1839e+01  ...  -2.6713e-05 -1.9607e+01 -1.5581e+01\n",
      "[torch.FloatTensor of size 200x10]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "-1.8580e+01 -1.0703e+01 -7.2218e-04  ...  -2.0949e+01 -1.1430e+01 -2.4591e+01\n",
      "-1.1945e+01 -6.1861e+00 -9.0068e+00  ...  -9.8317e+00 -3.7439e-01 -6.0617e+00\n",
      "-1.2168e+01 -9.4824e+00 -1.0244e-02  ...  -6.0111e+00 -1.0844e+01 -1.1851e+01\n",
      "                ...                   ⋱                   ...                \n",
      "-1.2923e+01 -1.4124e+01 -7.5179e+00  ...  -5.5389e-04 -1.5729e+01 -1.2949e+01\n",
      "-1.9188e+01 -1.7670e+01 -2.0426e+01  ...  -1.2454e+01 -1.4569e+01 -2.2273e-04\n",
      "-1.3455e+01 -8.9215e+00 -1.8963e+01  ...  -7.6043e+00 -8.5535e+00 -1.7456e-02\n",
      "[torch.FloatTensor of size 200x10]\n",
      "\n",
      "Variable containing:\n",
      "-2.7025e-05 -2.8071e+01 -1.2802e+01  ...  -1.8264e+01 -1.6737e+01 -1.0630e+01\n",
      "-1.0220e+01 -1.7922e+01 -9.9990e+00  ...  -1.6564e+01 -3.9369e-04 -9.2089e+00\n",
      "-1.9237e+01 -2.1748e+01 -2.0522e+01  ...  -1.0877e+01 -1.2362e+01 -2.9240e-05\n",
      "                ...                   ⋱                   ...                \n",
      "-8.8322e-04 -2.0495e+01 -1.8755e+01  ...  -1.7421e+01 -1.8010e+01 -1.7614e+01\n",
      "-9.4791e+00 -1.7719e+01 -1.2823e+01  ...  -1.5386e+01 -9.5789e-04 -7.2098e+00\n",
      "-1.7490e+01 -1.6568e+01 -1.3496e+01  ...  -1.4451e+01 -1.2978e+01 -4.7257e-04\n",
      "[torch.FloatTensor of size 200x10]\n",
      "\n",
      "Variable containing:\n",
      "-4.9182e+00 -1.7499e+01 -5.5329e+00  ...  -5.9795e-02 -1.1271e+01 -3.0631e+00\n",
      "-9.6645e+00 -1.8738e+01 -1.2566e-04  ...  -1.2458e+01 -1.0097e+01 -1.6348e+01\n",
      "-2.1588e+01 -3.1716e+01 -2.0563e+01  ...  -2.8605e+01 -2.4497e+01 -3.3852e+01\n",
      "                ...                   ⋱                   ...                \n",
      "-1.9336e+01 -1.7805e+01 -1.2490e+01  ...  -1.1397e+01 -1.1784e+01 -1.3769e+01\n",
      "-1.6434e+01 -1.4208e+01 -1.5776e+01  ...  -1.8881e+01 -1.0942e+01 -1.5522e+01\n",
      "-1.7405e+01 -8.1330e-04 -1.2546e+01  ...  -8.2782e+00 -8.5889e+00 -1.1296e+01\n",
      "[torch.FloatTensor of size 200x10]\n",
      "\n",
      "Variable containing:\n",
      "-8.0070e+00 -1.7079e+01 -8.5933e+00  ...  -7.0409e+00 -6.4319e+00 -5.0302e-03\n",
      "-5.7543e-07 -2.4562e+01 -1.6666e+01  ...  -1.6265e+01 -2.4431e+01 -2.0900e+01\n",
      "-8.7034e+00 -4.2818e+00 -5.4915e+00  ...  -1.1475e+01 -8.3486e+00 -1.7478e+01\n",
      "                ...                   ⋱                   ...                \n",
      "-1.2894e+01 -1.7980e+01 -1.6899e+01  ...  -6.8713e+00 -1.3423e+01 -1.2030e-03\n",
      "-2.0267e-04 -2.5812e+01 -1.4100e+01  ...  -1.5233e+01 -1.6213e+01 -8.7172e+00\n",
      "-1.6168e+01 -1.4564e+01 -1.4512e+01  ...  -1.0009e+01 -1.1347e+01 -1.8359e-03\n",
      "[torch.FloatTensor of size 200x10]\n",
      "\n",
      "Variable containing:\n",
      "-1.1325e+01 -1.1508e+01 -1.4566e+01  ...  -2.3438e+01 -9.7121e+00 -1.6977e+01\n",
      "-2.7105e+01 -1.1170e+01 -2.9733e-05  ...  -1.9868e+01 -1.8673e+01 -3.0131e+01\n",
      "-1.2046e+01 -1.3651e+01 -6.3148e+00  ...  -1.5784e+01 -7.4384e+00 -1.2936e+01\n",
      "                ...                   ⋱                   ...                \n",
      "-7.9862e+00 -2.0244e+01 -1.1208e+01  ...  -1.7834e+01 -4.5239e-03 -6.5340e+00\n",
      "-1.4135e+01 -1.5351e+01 -1.0583e+01  ...  -1.3435e+01 -1.3650e+01 -9.9549e+00\n",
      "-1.3749e+01 -1.1645e+01 -6.7554e-03  ...  -5.3096e+00 -1.2878e+01 -1.5760e+01\n",
      "[torch.FloatTensor of size 200x10]\n",
      "\n",
      "Variable containing:\n",
      "-1.7633e+01 -1.9852e+01 -1.0333e+01  ...  -4.2137e-05 -2.0285e+01 -1.5993e+01\n",
      "-2.3892e+01 -1.8081e+01 -1.8859e+01  ...  -1.7255e+01 -1.5985e+01 -1.1340e+01\n",
      "-9.8333e+00 -1.6476e+01 -1.3965e+01  ...  -1.8857e+01 -9.2614e-04 -7.0596e+00\n",
      "                ...                   ⋱                   ...                \n",
      "-9.3682e+00 -7.6798e+00 -2.0715e-02  ...  -4.7892e+00 -4.5623e+00 -1.2517e+01\n",
      "-1.9032e+01 -1.4986e+01 -1.2219e+01  ...  -4.4105e-05 -1.9821e+01 -1.4335e+01\n",
      "-9.4155e+00 -1.7467e+01 -1.5320e+01  ...  -1.2635e+01 -5.9109e+00 -2.4059e-02\n",
      "[torch.FloatTensor of size 200x10]\n",
      "\n",
      "Variable containing:\n",
      "-1.3565e+01 -3.2746e-03 -7.8892e+00  ...  -5.9205e+00 -9.0338e+00 -1.3433e+01\n",
      "-2.0497e+01 -1.6024e+01 -6.4508e-07  ...  -1.5590e+01 -1.7323e+01 -2.4631e+01\n",
      "-1.1451e+01 -7.4143e+00 -4.9719e-01  ...  -9.6358e-01 -9.5323e+00 -1.1392e+01\n",
      "                ...                   ⋱                   ...                \n",
      "-4.6054e-05 -2.0797e+01 -1.5189e+01  ...  -1.5090e+01 -1.8892e+01 -1.4894e+01\n",
      "-1.8590e+01 -2.3507e+01 -1.6608e+01  ...  -1.4651e+01 -1.0181e+01 -5.5590e-05\n",
      "-1.8343e+01 -9.4751e+00 -1.9024e-04  ...  -1.3171e+01 -1.6657e+01 -2.3594e+01\n",
      "[torch.FloatTensor of size 200x10]\n",
      "\n",
      "Variable containing:\n",
      "-2.1719e+01 -2.0006e+01 -1.9109e+01  ...  -1.7509e+01 -1.7544e+01 -1.6857e+01\n",
      "-1.3854e-01 -1.9395e+01 -1.3795e+01  ...  -8.7891e+00 -1.3816e+01 -2.0920e+00\n",
      "-1.8529e+01 -2.7877e+01 -1.4180e+01  ...  -3.0056e+01 -1.0619e-05 -1.4754e+01\n",
      "                ...                   ⋱                   ...                \n",
      "-1.4485e+01 -2.4556e+01 -1.4400e+01  ...  -2.4098e+01 -2.0672e+01 -3.0732e+01\n",
      "-1.0435e+01 -1.6359e+01 -1.3952e+01  ...  -7.8883e+00 -9.8990e+00 -6.1901e-04\n",
      "-1.6077e+01 -1.8012e+01 -2.0061e+01  ...  -1.0873e+01 -9.9807e+00 -1.4446e-04\n",
      "[torch.FloatTensor of size 200x10]\n",
      "\n",
      "Variable containing:\n",
      "-2.4922e-03 -1.6803e+01 -9.8820e+00  ...  -1.2441e+01 -1.3131e+01 -1.0629e+01\n",
      "-3.9643e-06 -2.7106e+01 -1.2623e+01  ...  -2.1259e+01 -1.8592e+01 -1.4562e+01\n",
      "-2.6864e-01 -1.4604e+01 -1.4507e+00  ...  -1.4956e+01 -9.5903e+00 -1.4105e+01\n",
      "                ...                   ⋱                   ...                \n",
      "-1.9124e+01 -2.0644e+01 -1.3638e+01  ...  -2.1699e+01 -1.5464e+01 -2.2065e+01\n",
      "-1.8527e+01 -8.2198e+00 -1.0436e+01  ...  -1.2155e+01 -7.7376e+00 -9.9260e+00\n",
      "-7.3682e+00 -6.7369e+00 -7.8189e+00  ...  -8.6612e+00 -4.0576e+00 -1.2742e+01\n",
      "[torch.FloatTensor of size 200x10]\n",
      "\n",
      "Variable containing:\n",
      "-9.2424e+00 -1.0880e+01 -1.5022e+01  ...  -8.9365e+00 -5.4978e-02 -1.1104e+01\n",
      "-2.0348e+01 -1.1603e+01 -4.9937e-05  ...  -1.6838e+01 -1.7417e+01 -3.2885e+01\n",
      "-1.8074e+01 -1.0655e+01 -9.4951e+00  ...  -1.4826e+01 -9.1604e+00 -1.6490e+01\n",
      "                ...                   ⋱                   ...                \n",
      "-2.3096e+01 -1.6353e+01 -2.1108e+01  ...  -2.5469e+01 -2.0263e+01 -1.7611e+01\n",
      "-1.7051e+01 -2.0824e+01 -1.2032e+01  ...  -2.0916e+01 -1.7337e+01 -2.6042e+01\n",
      "-1.3409e+01 -1.3823e+01 -9.9900e+00  ...  -1.1096e+01 -1.5615e+01 -8.9827e+00\n",
      "[torch.FloatTensor of size 200x10]\n",
      "\n",
      "Variable containing:\n",
      "-1.8485e+01 -1.3321e+01 -1.5898e+01  ...  -1.6350e+01 -7.8269e-05 -1.5829e+01\n",
      "-1.1670e+01 -1.1077e+01 -8.2832e+00  ...  -1.1066e+01 -3.3646e-01 -4.7996e+00\n",
      "-1.4176e+01 -4.5772e-03 -9.9853e+00  ...  -6.3903e+00 -6.9567e+00 -7.3771e+00\n",
      "                ...                   ⋱                   ...                \n",
      "-1.9088e+01 -1.6309e+01 -1.1527e+01  ...  -1.4585e+01 -1.0014e+01 -9.0970e+00\n",
      "-1.6754e+01 -1.6611e-03 -7.0659e+00  ...  -7.1313e+00 -1.3938e+01 -2.0957e+01\n",
      "-1.5030e+01 -1.3686e+01 -1.7921e+01  ...  -8.1231e+00 -1.3597e+01 -8.2325e-04\n",
      "[torch.FloatTensor of size 200x10]\n",
      "\n",
      "Variable containing:\n",
      "-1.2052e+01 -1.5551e+01 -1.1295e+01  ...  -1.5485e+01 -8.3404e-05 -1.0901e+01\n",
      "-1.5352e+01 -6.8211e-04 -1.0745e+01  ...  -7.4386e+00 -1.0596e+01 -1.4796e+01\n",
      "-9.5625e+00 -1.4052e+01 -7.9448e+00  ...  -1.5085e+01 -4.5009e-04 -1.3275e+01\n",
      "                ...                   ⋱                   ...                \n",
      "-1.3352e+01 -3.4160e-01 -3.1939e+00  ...  -8.7615e+00 -4.1099e+00 -1.2278e+01\n",
      "-1.5871e+01 -2.1223e+01 -1.4326e+01  ...  -1.7750e+01 -2.1245e-05 -1.2540e+01\n",
      "-1.1462e+01 -1.1122e+01 -1.0551e+01  ...  -1.6198e+01 -6.4222e+00 -7.6388e+00\n",
      "[torch.FloatTensor of size 200x10]\n",
      "\n",
      "Variable containing:\n",
      "-1.5765e+01 -2.4447e+01 -1.9446e+01  ...  -1.4251e+01 -6.5808e+00 -1.3955e-03\n",
      "-2.2834e+01 -7.4438e+00 -1.8739e-03  ...  -1.5400e+01 -1.4927e+01 -2.6440e+01\n",
      "-1.3228e+01 -8.3105e+00 -9.5932e+00  ...  -4.8591e-04 -1.1750e+01 -8.9937e+00\n",
      "                ...                   ⋱                   ...                \n",
      "-9.4495e+00 -9.8652e+00 -2.8642e-02  ...  -1.4315e+01 -1.3222e+01 -2.4519e+01\n",
      "-2.1841e+01 -6.0814e-05 -1.4708e+01  ...  -1.0855e+01 -1.0983e+01 -1.4755e+01\n",
      "-1.7209e+01 -1.8894e+01 -1.7966e+01  ...  -1.7037e+01 -1.3476e+01 -1.1769e+01\n",
      "[torch.FloatTensor of size 200x10]\n",
      "\n",
      "Variable containing:\n",
      "-2.2468e+01 -1.8414e+01 -1.7762e+01  ...  -1.5343e+01 -1.6780e+01 -1.4240e+01\n",
      "-8.4066e-05 -2.5767e+01 -1.3680e+01  ...  -1.1547e+01 -1.7709e+01 -9.5336e+00\n",
      "-1.6157e+01 -2.2947e+01 -2.0039e+01  ...  -1.0986e+01 -1.3192e+01 -2.4441e-05\n",
      "                ...                   ⋱                   ...                \n",
      "-2.3535e+01 -2.1904e+01 -1.5983e+01  ...  -1.4469e+01 -1.9209e+01 -1.5634e+01\n",
      "-1.1470e+01 -7.8306e+00 -4.9374e+00  ...  -8.9224e+00 -2.5984e+00 -7.3820e+00\n",
      "-1.5943e+01 -2.0983e+01 -1.7528e+01  ...  -2.8935e+01 -1.5797e+01 -2.5141e+01\n",
      "[torch.FloatTensor of size 200x10]\n",
      "\n",
      "Variable containing:\n",
      "-1.8101e+01 -3.5989e-04 -1.2354e+01  ...  -8.0001e+00 -1.2433e+01 -1.6325e+01\n",
      "-9.6288e+00 -1.7590e+01 -2.7209e-04  ...  -8.5127e+00 -1.5743e+01 -1.9611e+01\n",
      "-1.2508e+01 -1.8549e+01 -7.7764e+00  ...  -1.1522e+01 -1.8201e-03 -6.7276e+00\n",
      "                ...                   ⋱                   ...                \n",
      "-1.8993e+01 -1.7777e+01 -1.1084e+01  ...  -5.2119e-05 -1.8544e+01 -1.5967e+01\n",
      "-7.7788e+00 -2.4772e+00 -1.1512e-01  ...  -4.5792e+00 -6.3712e+00 -1.1253e+01\n",
      "-1.0317e+01 -1.7026e+01 -1.6139e+01  ...  -2.4712e+01 -1.1327e-04 -1.0044e+01\n",
      "[torch.FloatTensor of size 200x10]\n",
      "\n",
      "Variable containing:\n",
      "-6.4821e+00 -5.1082e+00 -2.7227e+00  ...  -1.0181e+01 -1.0380e+01 -9.5607e+00\n",
      "-1.0853e+01 -9.6252e+00 -1.3661e-02  ...  -5.7859e+00 -4.8039e+00 -1.4699e+01\n",
      "-1.6317e+01 -3.6050e-04 -1.3007e+01  ...  -8.4453e+00 -8.9681e+00 -1.4262e+01\n",
      "                ...                   ⋱                   ...                \n",
      "-2.0849e+01 -2.0325e+01 -1.8284e+01  ...  -2.8868e+01 -1.9799e+01 -1.9205e+01\n",
      "-2.1035e+01 -1.6152e+01 -1.5826e+01  ...  -2.5712e+01 -1.4779e+01 -1.6665e+01\n",
      "-5.8215e+00 -7.4529e+00 -3.2616e+00  ...  -1.1732e+01 -2.3946e+00 -8.9434e+00\n",
      "[torch.FloatTensor of size 200x10]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "-7.1720e+00 -1.6453e+01 -5.3565e+00  ...  -1.9497e+01 -6.9244e-03 -1.8122e+01\n",
      "-1.8447e+01 -1.6855e+01 -1.6334e+01  ...  -7.5155e+00 -1.2385e+01 -3.8080e-02\n",
      "-1.4245e+01 -7.7685e+00 -7.7258e+00  ...  -1.1144e-02 -1.0544e+01 -6.7533e+00\n",
      "                ...                   ⋱                   ...                \n",
      "-1.1832e-06 -2.6852e+01 -1.8506e+01  ...  -1.6920e+01 -2.2299e+01 -1.3984e+01\n",
      "-5.0338e-06 -2.8400e+01 -1.2775e+01  ...  -1.8549e+01 -1.9943e+01 -1.3031e+01\n",
      "-7.6536e+00 -1.9079e+01 -5.0249e+00  ...  -6.9320e+00 -8.1065e+00 -6.6969e+00\n",
      "[torch.FloatTensor of size 200x10]\n",
      "\n",
      "Variable containing:\n",
      "-1.0317e+01 -1.5858e+01 -4.5486e-05  ...  -1.4406e+01 -1.6783e+01 -1.6743e+01\n",
      "-1.6530e+01 -2.1856e+01 -1.2808e+01  ...  -1.2639e+01 -1.3966e+01 -1.3213e+01\n",
      "-1.3652e+01 -1.9758e+01 -1.4181e+01  ...  -6.3650e-06 -1.7075e+01 -1.2406e+01\n",
      "                ...                   ⋱                   ...                \n",
      "-1.6265e+01 -1.4236e+01 -1.4142e-04  ...  -2.4732e+01 -1.4220e+01 -2.9555e+01\n",
      "-1.7108e+01 -6.3047e-04 -1.2419e+01  ...  -7.4059e+00 -1.1608e+01 -1.4891e+01\n",
      "-4.4001e-05 -2.4965e+01 -1.4340e+01  ...  -2.2147e+01 -1.1894e+01 -1.7771e+01\n",
      "[torch.FloatTensor of size 200x10]\n",
      "\n",
      "Variable containing:\n",
      "-1.7682e+01 -1.4662e+01 -1.9611e-02  ...  -3.9679e+00 -1.9302e+01 -2.1228e+01\n",
      "-1.8041e+01 -1.8921e+01 -1.4250e+01  ...  -2.2675e+01 -1.7402e+01 -2.3594e+01\n",
      "-1.8647e+01 -9.9691e+00 -5.8826e-05  ...  -1.4863e+01 -1.3260e+01 -2.5078e+01\n",
      "                ...                   ⋱                   ...                \n",
      "-1.6216e+01 -1.5907e+01 -1.2374e+01  ...  -1.4015e+01 -1.7668e+01 -1.1860e+01\n",
      "-1.2625e+01 -1.3876e+01 -1.1332e+01  ...  -7.1365e+00 -9.5941e+00 -7.7191e-03\n",
      "-3.3401e-07 -2.7673e+01 -1.5778e+01  ...  -1.9916e+01 -2.0541e+01 -1.6095e+01\n",
      "[torch.FloatTensor of size 200x10]\n",
      "\n",
      "Variable containing:\n",
      "-2.0745e+01 -1.8792e+01 -7.8318e-07  ...  -1.6311e+01 -2.1206e+01 -2.8196e+01\n",
      "-1.8963e+01 -1.7261e+01 -2.1356e+01  ...  -2.3853e+01 -1.7661e+01 -1.5939e+01\n",
      "-1.7330e+01 -9.0499e-04 -1.3434e+01  ...  -7.0344e+00 -1.2093e+01 -1.4735e+01\n",
      "                ...                   ⋱                   ...                \n",
      "-1.4893e+01 -1.6218e+01 -1.4599e+01  ...  -8.1940e+00 -1.0590e+01 -3.2213e-04\n",
      "-2.0560e+01 -1.9942e+01 -1.3170e+01  ...  -1.0365e-05 -1.9796e+01 -1.7568e+01\n",
      "-1.6108e+01 -1.8276e-03 -1.0224e+01  ...  -1.5522e+01 -7.1565e+00 -1.4683e+01\n",
      "[torch.FloatTensor of size 200x10]\n",
      "\n",
      "Variable containing:\n",
      "-1.5846e+01 -1.4652e+01 -1.7136e+01  ...  -8.3549e+00 -1.0575e+01 -2.9938e-04\n",
      "-8.3960e-06 -2.4257e+01 -1.1803e+01  ...  -1.6887e+01 -1.7580e+01 -1.4400e+01\n",
      "-1.6317e-03 -1.6554e+01 -7.3463e+00  ...  -1.1961e+01 -9.6328e+00 -7.0420e+00\n",
      "                ...                   ⋱                   ...                \n",
      "-1.3840e+01 -1.0081e+01 -1.2360e+01  ...  -2.1480e-04 -1.1680e+01 -9.3939e+00\n",
      "-2.1437e+01 -8.3467e-05 -1.4899e+01  ...  -1.0108e+01 -1.0646e+01 -1.3671e+01\n",
      "-2.1510e+01 -1.6331e+01 -5.9011e-07  ...  -1.7100e+01 -1.9917e+01 -2.8406e+01\n",
      "[torch.FloatTensor of size 200x10]\n",
      "\n",
      "\n",
      "Test set: Average loss: 0.0003, Accuracy: 9776/10000 (98%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_loss = 0\n",
    "correct = 0\n",
    "for data, target in test_loader:\n",
    "    data, target = Variable(data, volatile=True), Variable(target)\n",
    "    data = data.view(-1, 28 * 28)\n",
    "    net_out = fcn_i1(data)\n",
    "    #print(net_out)\n",
    "    # sum up batch loss\n",
    "    test_loss += criterion(net_out, target).data[0]\n",
    "    pred = net_out.data.max(1)[1]  # get the index of the max log-probability\n",
    "    correct += pred.eq(target.data).sum()\n",
    "\n",
    "test_loss /= len(test_loader.dataset)\n",
    "print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensor_comprehensions as tc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "[n_W,n_b]=fcn_i1.print_param()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lang = \"\"\"\n",
    "#def fcrelu(float(B,M) I, float(N,M) W1, float(N) B1) -> (O1) {\n",
    "#    O1(b, n) +=! I(b, m) * W1(n, m)\n",
    "#    O1(b, n) = O1(b, n) + B1(n)\n",
    "#    O1(b, n) = fmax(O1(b, n), 0)\n",
    "#}\n",
    "#\"\"\"\n",
    "\n",
    "#lang1 = \"\"\"\n",
    "#def fc(float(B,M) I, float(N,M) W1,float(N) B1) -> (O1){\n",
    "#     O1(b, n)+=! I(b,m)* W1(n, m)\n",
    "#     O1(b, n) = O1(b, n) + B1(n)\n",
    "#}\n",
    "#\"\"\"\n",
    "\n",
    "#lang2=\"\"\"\n",
    "#def softmax(float(N, D) I) -> (O, maxVal, expDistance, expSum) {\n",
    "#    maxVal(n) max=! I(n, d)\n",
    "#    expDistance(n, d) = exp(I(n, d) - maxVal(n))\n",
    "#    expSum(n) +=! expDistance(n, d)\n",
    "#    O(n, d) = expDistance(n, d) / expSum(n)\n",
    "#}\n",
    "#\"\"\"\n",
    "\n",
    "#fcrelu = tc.define(lang, name=\"fcrelu\")\n",
    "#fc=tc.define(lang1,name=\"fc\")\n",
    "#softmax=tc.define(lang2,name=\"softmax\")\n",
    "\n",
    "lang = \"\"\"\n",
    "def fcrelunet(float(B,M) I, float(N,M) W1, float(N) B1,float(P,N) W2, float(P) B2,float(Q,P) W3, float(Q) B3) -> (O1,O2,O3,O4,O5,maxVal, expDistance, expSum) {\n",
    "    O1(b, n) +=! I(b, m) * W1(n, m)\n",
    "    O1(b, n) = O1(b, n) + B1(n)\n",
    "    O1(b, n) = fmax(O1(b, n), 0)\n",
    "    O2(b, p) +=! O1(b, n) * W2(p, n)\n",
    "    O2(b, p) = O2(b, p) + B2(p)\n",
    "    O2(b, p) = fmax(O2(b, p), 0)\n",
    "    O3(b, q) +=! O2(b, p) * W3(q, p)\n",
    "    O3(b, q) = O3(b, q) + B3(q)\n",
    "    maxVal(b) max=! O3(b , q)\n",
    "    expDistance(b ,q) = exp(O3(b , q) - maxVal(b))\n",
    "    expSum(b) +=! expDistance(b , q)\n",
    "    O4(b , q) = expDistance(b , q) / expSum(b)\n",
    "    O5(b, q) = log(O4(b , q))\n",
    "}\n",
    "\"\"\"\n",
    "#O5(b , q) = log(O4(b , q))\n",
    "fcrelunet = tc.define(lang, name=\"fcrelunet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]: Autotuning cache will be saved to: fcrelu_784_200_200_10.tc.cuda/options\n",
      "[INFO]: Tuned kernel options found, using those options\n"
     ]
    }
   ],
   "source": [
    "#B_1,B_2, M, N = 28*28,1, 200, 200\n",
    "# I= torch.ones(B_2, B_1).cuda() \n",
    "#W1, B1=torch.ones(M, B_1).cuda(), torch.ones(N).cuda()\n",
    "#W1=n_W[0].cuda()\n",
    "#B1=n_b[0].cuda()\n",
    "#out1=torch.ones(B_2,N)\n",
    "#W2=n_W[1].cuda()\n",
    "#B2=n_b[1].cuda()\n",
    "#W3=n_W[2].cuda()\n",
    "#B3=n_b[2].cuda()\n",
    "\n",
    "#fcrelu.autotune(I, W1, B1, cache=\"fcrelu_784_200_200.tc\")\n",
    "#out = fcrelu(I, W1, B1)\n",
    "\n",
    "ID,B,M,N,P,Q=1,28*28,200,200,200,10\n",
    "I= torch.ones(ID, B).cuda()\n",
    "#W1=torch.ones(M, B).cuda()\n",
    "#B1=torch.ones(N).cuda()\n",
    "#W2=torch.ones(P, N).cuda()\n",
    "#B2=torch.ones(P).cuda() \n",
    "#W3=torch.ones(Q, P).cuda()\n",
    "#B3=torch.ones(Q).cuda()\n",
    "W1=n_W[0].cuda()\n",
    "B1=n_b[0].cuda()\n",
    "W2=n_W[1].cuda()\n",
    "B2=n_b[1].cuda()\n",
    "W3=n_W[2].cuda()\n",
    "B3=n_b[2].cuda()\n",
    "#print(I.size())\n",
    "#print(W1.size())\n",
    "#print(B1.size())\n",
    "#print(W2.size())\n",
    "#print(B2.size())\n",
    "#print(W3.size())\n",
    "#print(B3.size())\n",
    "#print(\"Actual Sizes\")\n",
    "#print(n_W[0].size())\n",
    "#print(n_b[0].size())\n",
    "#print(n_W[1].size())\n",
    "#print(n_b[1].size())\n",
    "#print(n_W[2].size())\n",
    "#print(n_b[2].size())\n",
    "fcrelunet.autotune(I, W1, B1, W2 , B2, W3, B3, cache=\"fcrelu_784_200_200_10.tc\")\n",
    "out=fcrelunet(I,W1,B1,W2,B2,W3,B3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "-5.9052 -1.9317 -3.5153 -0.4119 -5.9560 -2.4734 -6.9082 -2.7193 -5.7613 -5.7132\n",
      "[torch.cuda.FloatTensor of size 1x10 (GPU 0)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(out[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Time on 10 iterations for cpu:\n",
      "0.72568000257\n",
      "Max Time on 10 iterations for cpu:\n",
      "2.27350401878\n",
      "Min Time on 10 iterations for cpu:\n",
      "0.283903986216\n",
      "Variable containing:\n",
      "-5.9052 -1.9317 -3.5153 -0.4119 -5.9560 -2.4734 -6.9082 -2.7193 -5.7613 -5.7132\n",
      "[torch.FloatTensor of size 1x10]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kushal/anaconda3/envs/ece587_ptc/lib/python3.6/site-packages/ipykernel_launcher.py:16: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "d=Variable(torch.ones(ID,B),requires_grad=False)\n",
    "time=[]\n",
    "for i in range(10):\n",
    "    start = torch.cuda.Event(enable_timing=True)\n",
    "    end = torch.cuda.Event(enable_timing=True)\n",
    "    start.record()\n",
    "    n_out=fcn_i1(d)\n",
    "    end.record()\n",
    "    torch.cuda.synchronize()\n",
    "    time.append(start.elapsed_time(end))\n",
    "\n",
    "time=np.array(time)\n",
    "print('Mean Time on 10 iterations for cpu:')\n",
    "print(np.mean(time))\n",
    "print('Max Time on 10 iterations for cpu:')\n",
    "print(np.max(time))\n",
    "print('Min Time on 10 iterations for cpu:')\n",
    "print(np.min(time))\n",
    "print(n_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
